{"cells":[{"cell_type":"markdown","source":["# Import library"],"metadata":{"id":"5nGiHHlNpdat"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"AzqaYy33QrgS"},"outputs":[],"source":["from PIL import Image\n","import os\n","import torch\n","import torchvision\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms, datasets\n","from torchvision.utils import save_image\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"markdown","source":["# Read Data"],"metadata":{"id":"8uz7Zo9UpUbJ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18625,"status":"ok","timestamp":1654477792274,"user":{"displayName":"전준형","userId":"14189242397168360494"},"user_tz":-540},"id":"qclrFw6BQfRR","outputId":"8cd1bc88-c115-4f8a-fc42-0a8089c6d831"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}],"source":["from google.colab import drive \n","drive.mount('/content/gdrive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6128,"status":"ok","timestamp":1654477798400,"user":{"displayName":"전준형","userId":"14189242397168360494"},"user_tz":-540},"id":"LGmAeUYPr7g4","outputId":"d8e0df6f-78fe-4c94-98d9-e68122f40122"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1098"]},"metadata":{},"execution_count":3}],"source":["from glob import glob\n","val_file = glob(f'/content/gdrive/MyDrive/Colab Notebooks/maps/val/*')\n","len(val_file)"]},{"cell_type":"markdown","source":["# Dataset functions"],"metadata":{"id":"RcTqBi6Rpmd5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hldLsKHX4_L_"},"outputs":[],"source":["def tensor_to_image(data):\n","  return  unnormalize(np.transpose(data.detach().cpu().numpy()[0] , (1, 2, 0)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zpOOzzAHtMJ-"},"outputs":[],"source":["def file_to_PIL(sample):\n","  \n","  result = Image.open(sample)\n","\n","  return result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"92VzT1VmZWSq"},"outputs":[],"source":["def splitTensor(sample):\n","        C, H, W = sample.shape\n","        \n","        input_image = sample[:,:,:int(W/2)]\n","        target_image = sample[:,:,int(W/2):]\n","        \n","        output = torch.cat([input_image,target_image])\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Se1XqqCqhNzZ"},"outputs":[],"source":["def make_two_tensor(sample):\n","  C, H, W = sample.shape   \n","  input_image = sample[:int(C/2),:,:]\n","  target_image = sample[int(C/2):,:,:] \n","\n","  return input_image, target_image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z-3j8GZTFjt9"},"outputs":[],"source":["def split_input_tensor(sample):\n","  C, H, W = sample.shape\n","        \n","  input_image = sample[:,:,:int(W/2)]\n","  target_image = sample[:,:,int(W/2):]\n","  \n","  output = torch.cat([input_image,target_image])\n","\n","  return input_image, target_image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7i1kSQvNyihx"},"outputs":[],"source":["def unnormalize(sample):\n","  sample = ((sample * 0.5) + 0.5)\n","  return sample"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ooHIFnhEHwWp"},"outputs":[],"source":["def shuffle_batch(data):\n","  if len(data) == 1:\n","    return data\n","  first_data = data[0].clone()\n","  data[0:-1] = data[1:].clone()\n","  data[-1] = first_data\n","  return data"]},{"cell_type":"markdown","source":["# Dataset"],"metadata":{"id":"JamvW__2rqTK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_NtMcedAcEEd"},"outputs":[],"source":["image_height = 256\n","image_width = 256"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2WAVTMhotgcp"},"outputs":[],"source":["class CustomDatasest(Dataset):\n","  def __init__(self, np_data, transform = None):\n","      self.data = np_data\n","      self.transform = transform\n","      self.len = len(np_data)\n","\n","  def __len__(self):\n","    return self.len\n","\n","  def __getitem__(self, idx):\n","    sample = self.data[idx]\n","    if self.transform:\n","      sample = self.transform(sample)\n","    return sample"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zeGW6f7ndEuf"},"outputs":[],"source":["trans = transforms.Compose([\n","                            file_to_PIL,\n","                            transforms.ToTensor(),\n","                            transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n","                            transforms.Resize((image_height, image_width*2)),\n","                            splitTensor,\n","                            make_two_tensor,\n","                            ])"]},{"cell_type":"markdown","metadata":{"id":"wN-dS6uqr6u2"},"source":["# DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yKRAJxqvdQJK"},"outputs":[],"source":["val_dataset = CustomDatasest(val_file, transform = trans)\n","val_loader = DataLoader(\n","    dataset = val_dataset, \n","    batch_size = 1\n",")"]},{"cell_type":"markdown","metadata":{"id":"-RRjYTXnQkoy"},"source":["#Pix2Pix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yaq1D0XUQgQt"},"outputs":[],"source":["class Pix2pixGenerator(nn.Module):\n","    def __init__(self, output_nc):\n","        super(Pix2pixGenerator, self).__init__()\n","\n","        self.downsample_layers = []\n","        # Downsampling\n","        in_features = 3\n","        out_features = 64\n","        \n","        input = nn.Sequential(*self.downsample(in_features,out_features,False))\n","        self.downsample_layers.append(input) #(128, 128, 64)\n","\n","        in_features = out_features\n","        out_features = out_features * 2\n","        \n","        input = nn.Sequential(*self.downsample(in_features,out_features))\n","        self.downsample_layers.append(input) #(64, 64, 128)\n","\n","        in_features = out_features\n","        out_features = out_features * 2\n","        \n","        input = nn.Sequential(*self.downsample(in_features,out_features))\n","        self.downsample_layers.append(input) # (32, 32, 256)\n","\n","        in_features = out_features\n","        out_features = out_features * 2\n","\n","        input = nn.Sequential(*self.downsample(in_features,out_features))\n","        self.downsample_layers.append(input) # (16, 16, 512)\n","\n","        in_features = out_features\n","\n","        self.downsample_layers.append(nn.Sequential(*self.downsample(in_features,out_features))) # (8, 8, 512)\n","        self.downsample_layers.append(nn.Sequential(*self.downsample(in_features,out_features))) # (4, 4, 512)\n","        self.downsample_layers.append(nn.Sequential(*self.downsample(in_features,out_features))) # (2, 2, 512)\n","        self.downsample_layers.append(nn.Sequential(*self.downsample(in_features,out_features))) # (1, 1, 512)\n","\n","        self.downsample_layer = nn.Sequential(*self.downsample_layers)\n","\n","        self.updsample_layers = []\n","\n","        self.updsample_layers.append(nn.Sequential(*self.upsample(in_features,out_features, apply_dropout=True))) # (2, 2, 512)\n","\n","        in_features = out_features * 2 # concat 1024\n","\n","        self.updsample_layers.append(nn.Sequential(*self.upsample(in_features,out_features, apply_dropout=True))) # (4, 4, 512)\n","        self.updsample_layers.append(nn.Sequential(*self.upsample(in_features,out_features, apply_dropout=True))) # (8, 8, 512)\n","        self.updsample_layers.append(nn.Sequential(*self.upsample(in_features,out_features))) # (16, 16, 512)\n","\n","        out_features = out_features // 2 # 256\n","\n","        self.updsample_layers.append(nn.Sequential(*self.upsample(in_features,out_features))) # (32, 32, 256)\n","\n","        in_features = out_features * 2 # 512\n","        out_features = out_features // 2 # 128\n","\n","        self.updsample_layers.append(nn.Sequential(*self.upsample(in_features,out_features))) # (64, 64, 128)\n","\n","        in_features = out_features * 2 # 256\n","        out_features = out_features // 2 #64\n","\n","        self.updsample_layers.append(nn.Sequential(*self.upsample(in_features,out_features))) # (128, 128, 64)\n","        \n","        in_features = out_features * 2\n","        out_features = output_nc\n","\n","        self.updsample_layer = nn.Sequential(*self.updsample_layers)\n","\n","        self.output_layer = nn.Sequential(\n","                                           nn.ConvTranspose2d(in_features, out_features, 4, stride=2, padding=1),\n","                                           nn.Tanh(),\n","        )\n","\n","    def downsample(self, in_features,out_features, apply_batchnorm=True):\n","      layerList = []\n","      layerList.append(nn.Conv2d(in_features, out_features, 4, stride=2, padding=1, bias=False))\n","      if apply_batchnorm:\n","        layerList.append(nn.BatchNorm2d(out_features))\n","      layerList.append(nn.LeakyReLU(0.3, inplace=True))\n","\n","      return layerList\n","\n","    def upsample(self, in_features,out_features, apply_dropout=True):\n","      layerList = []\n","      layerList.append(nn.ConvTranspose2d(in_features, out_features, 4, stride=2, padding=1, bias=False))\n","\n","      \n","      layerList.append(nn.BatchNorm2d(out_features))\n","      if apply_dropout:\n","        layerList.append(nn.Dropout(0.2))\n","      layerList.append(nn.LeakyReLU(0.3, inplace=True))\n","\n","      return layerList\n","\n","    def forward(self, x):\n","      \n","      down_result = []\n","      for i, down in enumerate(self.downsample_layers):\n","        x = down(x)\n","        down_result.append(x)\n","      down_result = reversed(down_result[:-1])\n","      for up, down in zip(self.updsample_layers, down_result):\n","        x = up(x)\n","        x = torch.cat([x, down], dim=1)\n","\n","      x = self.output_layer(x)\n","      return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lkX-3hp0QgQw"},"outputs":[],"source":["class Pix2pixDiscriminator(nn.Module):\n","    def __init__(self, input_nc):\n","        super(Pix2pixDiscriminator, self).__init__()\n","\n","        # A bunch of convolutions one after another\n","        self.downsample_layers = []\n","        # Downsampling\n","        in_features = input_nc * 2\n","        out_features = 64\n","        \n","        input = nn.Sequential(*self.downsample(in_features,out_features,False))\n","        self.downsample_layers.append(input) #(128, 128, 64)\n","\n","        in_features = out_features\n","        out_features = out_features * 2\n","        \n","        input = nn.Sequential(*self.downsample(in_features,out_features))\n","        self.downsample_layers.append(input) #(64, 64, 128)\n","\n","        in_features = out_features\n","        out_features = out_features * 2\n","        \n","        input = nn.Sequential(*self.downsample(in_features,out_features))\n","        self.downsample_layers.append(input) # (32, 32, 256)\n","\n","        self.downsample_layer = nn.Sequential(*self.downsample_layers)\n","\n","        in_features = out_features\n","        out_features = out_features * 2\n","\n","        self.zero_pad = nn.ZeroPad2d(1)\n","\n","        self.conv1 = nn.Conv2d(in_features, out_features, 4, stride=1, bias=False)\n","\n","        in_features = out_features\n","\n","        self.batchnorm = nn.BatchNorm2d(out_features)\n","        self.leakyRelu = nn.LeakyReLU(0.3, inplace=True)\n","        self.conv2 = nn.Conv2d(in_features, 1, 4, stride=1)\n","\n","    def downsample(self, in_features,out_features, apply_batchnorm=True):\n","      layerList = []\n","      layerList.append(nn.Conv2d(in_features, out_features, 4, stride=2, padding=1, bias=False))\n","      if apply_batchnorm:\n","        layerList.append(nn.BatchNorm2d(out_features))\n","      layerList.append(nn.LeakyReLU(0.3, inplace=True))\n","\n","      return layerList\n","\n","    def forward(self, inputImg, targetImg):\n","        x = torch.cat((inputImg,targetImg), dim=1)\n","        x = self.downsample_layer(x)\n","        x = self.zero_pad(x)\n","        x = self.conv1(x)\n","        x = self.batchnorm(x)\n","        x = self.leakyRelu(x)\n","        x = self.zero_pad(x)\n","        x = self.conv2(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"SSgvEyD6HccC"},"source":["#CycleGan"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sSb63dg3Xsb3"},"outputs":[],"source":["class ResidualBlock(nn.Module):\n","    def __init__(self, in_features):\n","        super(ResidualBlock, self).__init__()\n","\n","        conv_block = [  nn.ReflectionPad2d(1),\n","                        nn.Conv2d(in_features, in_features, 3),\n","                        nn.InstanceNorm2d(in_features),\n","                        nn.ReLU(inplace=True),\n","                        nn.Dropout(0.5),\n","                        nn.ReflectionPad2d(1),\n","                        nn.Conv2d(in_features, in_features, 3),\n","                        nn.InstanceNorm2d(in_features)]\n","\n","        self.conv_block = nn.Sequential(*conv_block)\n","\n","    def forward(self, x):\n","        return x + self.conv_block(x)"]},{"cell_type":"markdown","metadata":{"id":"1nChvycCHfXM"},"source":["## Generator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0jGyifMNXvJk"},"outputs":[],"source":["class Generator(nn.Module):\n","    def __init__(self, input_nc, output_nc, n_residual_blocks=9):\n","        super(Generator, self).__init__()\n","\n","        # Initial convolution block       \n","        model = [   nn.ReflectionPad2d(3),\n","                    nn.Conv2d(input_nc, 64, 7),\n","                    nn.InstanceNorm2d(64),\n","                    nn.ReLU(inplace=True) ]\n","\n","        # Downsampling\n","        in_features = 64\n","        out_features = in_features*2\n","        for _ in range(2):\n","            model += [  nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n","                        nn.InstanceNorm2d(out_features),\n","                        nn.ReLU(inplace=True) ]\n","            in_features = out_features\n","            out_features = in_features*2\n","\n","        # Residual blocks\n","        for _ in range(n_residual_blocks):\n","            model += [ResidualBlock(in_features)]\n","\n","        # Upsampling\n","        out_features = in_features//2\n","        for _ in range(2):\n","            model += [  nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n","                        nn.InstanceNorm2d(out_features),\n","                        nn.ReLU(inplace=True) ]\n","            in_features = out_features\n","            out_features = in_features//2\n","\n","        # Output layer\n","        model += [  nn.ReflectionPad2d(3),\n","                    nn.Conv2d(64, output_nc, 7),\n","                    nn.Tanh() ]\n","\n","        self.model = nn.Sequential(*model)\n","\n","    def forward(self, x):\n","        return self.model(x)"]},{"cell_type":"markdown","metadata":{"id":"RNRocnoxHhqX"},"source":["##Discriminator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EG3zb2iKXxZU"},"outputs":[],"source":["class Discriminator(nn.Module):\n","  def __init__(self, input_nc):\n","      super(Discriminator, self).__init__()\n","\n","      # A bunch of convolutions one after another\n","      model = [   nn.Conv2d(input_nc, 64, 4, stride=2, padding=1),\n","                  nn.LeakyReLU(0.2, inplace=True),\n","                  nn.Dropout(0.2)]\n","\n","      model += [  nn.Conv2d(64, 128, 4, stride=2, padding=1),\n","                  nn.InstanceNorm2d(128),\n","                  nn.LeakyReLU(0.2, inplace=True),\n","                  nn.Dropout(0.2) ]\n","\n","      model += [  nn.Conv2d(128, 256, 4, stride=2, padding=1),\n","                  nn.InstanceNorm2d(256),\n","                  nn.LeakyReLU(0.2, inplace=True),\n","                  nn.Dropout(0.2) ]\n","\n","      model += [  nn.Conv2d(256, 512, 4, 1, 1),\n","                  nn.InstanceNorm2d(512),\n","                  nn.LeakyReLU(0.2, inplace=True) ]\n","\n","      # FCN classification layer\n","      model += [nn.Conv2d(512, 1, 4, 1, 1)]\n","\n","      self.model = nn.Sequential(*model)\n","\n","  def forward(self, x):\n","    return self.model(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"72tgbVStROhw"},"outputs":[],"source":["pix2pix_netG = Pix2pixGenerator(3)\n","\n","default_netG_A2B = Generator(3, 3)\n","default_netG_B2A = Generator(3, 3)\n","\n","semi_netG_A2B = Generator(3, 3)\n","semi_netG_B2A = Generator(3, 3)"]},{"cell_type":"markdown","source":["# Load pix2pix"],"metadata":{"id":"NkGYhJX-qGvV"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5190,"status":"ok","timestamp":1654477807430,"user":{"displayName":"전준형","userId":"14189242397168360494"},"user_tz":-540},"id":"yeYunwQ_Q8rf","outputId":"f3ac1e43-ac6d-4871-be0a-02257a2bc8ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["199\n"]}],"source":["pix2pix_save_folder = f'/content/gdrive/MyDrive/Colab Notebooks/maps/pix2pix/' \n","pix2pix_file_name = f'pix2pix_model_2022-06-04 01:41:47.675579+09:00.pth_200.pth'\n","pix2pix_checkpoint = torch.load(f'{pix2pix_save_folder}{pix2pix_file_name}', map_location=torch.device('cpu'))\n","pix2pix_netG.load_state_dict(pix2pix_checkpoint['g_model_state_dict'])\n","print(pix2pix_checkpoint['epoch'])"]},{"cell_type":"markdown","source":["# Load cyclegan"],"metadata":{"id":"9cbquvOZqImM"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2171,"status":"ok","timestamp":1654477809599,"user":{"displayName":"전준형","userId":"14189242397168360494"},"user_tz":-540},"id":"HOSXYKQ1RRyu","outputId":"d811b8c4-3cf1-48ab-c647-acf058b226d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["150\n"]}],"source":["cyclegan_save_folder = f'/content/gdrive/MyDrive/Colab Notebooks/maps/cyclegan/'\n","cyclegan_file_name = f'cyclegan_model_2022-05-12 02:46:50.888392+09:00.pth'\n","cycle_gan_checkpoint = torch.load(f'{cyclegan_save_folder}{cyclegan_file_name}', map_location=torch.device('cpu'))\n","start_epoch = cycle_gan_checkpoint['epoch']\n","default_netG_A2B.load_state_dict(cycle_gan_checkpoint['netG_A2B_state_dict'])\n","default_netG_B2A.load_state_dict(cycle_gan_checkpoint['netG_B2A_state_dict'])\n","print(start_epoch)"]},{"cell_type":"markdown","source":["# Load semi-cyclegan"],"metadata":{"id":"83HtvUuiqKQ7"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3810,"status":"ok","timestamp":1654477813407,"user":{"displayName":"전준형","userId":"14189242397168360494"},"user_tz":-540},"id":"DPFGZb69RScu","outputId":"00b92ad3-c530-4954-b22b-300beb172834"},"outputs":[{"output_type":"stream","name":"stdout","text":["150\n"]}],"source":["save_model_folder = f'/content/gdrive/MyDrive/Colab Notebooks/maps/cyclegan_semi/'\n","file_name = f'150_semi_cyclegan_model_2022-05-15 13:50:11.965796+09:00.pth'\n","checkpoint = torch.load(f'{save_model_folder}{file_name}', map_location=torch.device('cpu'))\n","start_epoch = checkpoint['epoch']\n","semi_netG_A2B.load_state_dict(checkpoint['netG_A2B_state_dict'])\n","semi_netG_B2A.load_state_dict(checkpoint['netG_B2A_state_dict'])\n","print(start_epoch)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1654477813408,"user":{"displayName":"전준형","userId":"14189242397168360494"},"user_tz":-540},"id":"H0Jo25eTUL6K","outputId":"f9f224cf-aad9-416d-d468-bf75c34ee1fe"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}],"source":["device = 'cuda' if torch.cuda.is_available() else  'cpu'\n","device"]},{"cell_type":"markdown","source":["# Visualize GAN"],"metadata":{"id":"B52idknaqTGq"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10632,"status":"ok","timestamp":1654477824035,"user":{"displayName":"전준형","userId":"14189242397168360494"},"user_tz":-540},"id":"6BLsSBpMRiZS","outputId":"b5391caf-adbf-42c7-e5d8-04492ed4270d"},"outputs":[{"output_type":"stream","name":"stdout","text":["done\n"]}],"source":["val_iter = iter(val_loader)\n","\n","pix2pix_netG.to(device)\n","default_netG_A2B.to(device)\n","default_netG_B2A.to(device)\n","semi_netG_A2B.to(device)\n","semi_netG_B2A.to(device)\n","\n","pix2pix_netG.eval()\n","default_netG_A2B.eval()\n","default_netG_B2A.eval()\n","semi_netG_A2B.eval()\n","semi_netG_B2A.eval()\n","print(\"done\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1bu4VNPUMAy8u1Ym7ElQlq8wj9JCX7mnR"},"id":"liZ23KbqRqYj","outputId":"1ce659bb-ffbb-4fba-8c97-7e7f30e72247","executionInfo":{"status":"ok","timestamp":1654477843171,"user_tz":-540,"elapsed":13606,"user":{"displayName":"전준형","userId":"14189242397168360494"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["for _ in range(10):\n","  inputA, inputB = next(val_iter)\n","\n","\n","  with torch.no_grad():\n","    inputA = inputA.to(device)\n","    inputB = inputB.to(device)\n","\n","    pix2pix_fake_B = pix2pix_netG(inputA)\n","    default_fake_B = default_netG_A2B(inputA)\n","    semi_fake_B = semi_netG_A2B(inputA)\n","\n","    #default_fake_A = tensor_to_image(default_netG_B2A(inputB))\n","    #semi_fake_A = tensor_to_image(semi_netG_B2A(inputB))\n","\n","    fig = plt.figure(figsize=(30,30))\n","    fig.add_subplot(151)\n","    plt.axis('off')\n","    plt.imshow(tensor_to_image(inputA))\n","    fig.add_subplot(152)\n","    plt.axis('off')\n","    plt.imshow(tensor_to_image(inputB))\n","    fig.add_subplot(153)\n","    plt.imshow(tensor_to_image(pix2pix_fake_B))\n","    fig.add_subplot(154)\n","    plt.imshow(tensor_to_image(default_fake_B))\n","    fig.add_subplot(155)\n","    plt.imshow(tensor_to_image(semi_fake_B))\n","    \n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"9mJGol-CwRSD"},"source":["#Segmentation Labels"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1654421310349,"user":{"displayName":"전준형","userId":"14189242397168360494"},"user_tz":-540},"id":"5NgGfQQ-oqC6","outputId":"5cba6aee-e84e-46ba-cb88-7793cd488d86"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["8"]},"metadata":{},"execution_count":28}],"source":["label_colors = {}\n","label_colors['grass'] = [200,225,170]\n","label_colors['load'] = [255, 255, 255]\n","label_colors['arrow'] = [200,200,200]\n","label_colors['building'] = [243,240,233]\n","label_colors['building_floor'] = [233,228,222]\n","label_colors['playground'] = [232,221, 190]\n","label_colors['high_load'] = [250,160,40]\n","label_colors['water'] = [177,208, 255]\n","len(label_colors)"]},{"cell_type":"markdown","source":["# Evaluate Functions"],"metadata":{"id":"TpRaBJ92q8_W"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FSYpUx6RwILp"},"outputs":[],"source":["def make_label_map(image):\n","  H, W, C = image.shape\n","  feature_map = np.zeros((H,W,1)).astype(np.uint)\n","  for h in range(H):\n","    for w in range(W):\n","      label_index = 0\n","      min_distance = float(\"inf\")\n","      img_color = image[h, w, :]\n","      for i, label in enumerate(label_colors.values()):\n","        distance = ((img_color - label) ** 2).sum()\n","        if min_distance > distance:\n","          label_index = i\n","          min_distance = distance\n","      feature_map[h, w, 0] = label_index\n","  return feature_map"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"84UCAM0wy2iJ"},"outputs":[],"source":["def label_map_to_image(label_map):\n","  H, W, C = label_map.shape\n","  label_values = list(label_colors.values())\n","  result_image = np.zeros((H, W, 3)).astype(np.uint)\n","  for h in range(H):\n","    for w in range(W):\n","      result_image[h,w,:] = label_values[label_map[h,w,0]]\n","  return result_image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"66sxlPsbiWZ8"},"outputs":[],"source":["def get_pixel_accuracy(target_label, input_label):\n","  if target_label.shape != input_label.shape:\n","    print(\"Input Shape Error!\")\n","    return\n","  H, W, C = target_label.shape\n","  t_i = H * W\n","  correct_num = np.count_nonzero(target_label == input_label)\n","  return correct_num / t_i"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nGmjf-ptpc8X"},"outputs":[],"source":["def make_label_map_by_torch(image_tensor):\n","  H, W, C = image_tensor.shape\n","  device = image_tensor.get_device()\n","  feature_num = len(label_colors.values())\n","\n","  \n","  label_tensor = torch.Tensor(list(label_colors.values())).view(feature_num,1,1,3).repeat(1,H,W,1).to(device)\n","  image_tensor = torch.unsqueeze(image_tensor, 0).repeat(feature_num,1,1,1).to(device)\n","\n","  cal_result = (image_tensor - label_tensor).pow(2).sum(-1)\n","  _, ii = torch.min(cal_result, 0)\n","\n","  return ii"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_qsozmxCr7_f"},"outputs":[],"source":["def batch_tensor_to_image_tensor(input):\n","  result = input[0]\n","  result = (result * 0.5) + 0.5\n","  result = torch.permute(result, (1,2,0))\n","  return result * 255."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"39c99MTlddzI"},"outputs":[],"source":["def label_tensor_map_to_image(label_map):\n","  label_map = np.expand_dims(label_map.cpu().numpy(), -1)\n","\n","  H, W,C = label_map.shape\n","  label_values = list(label_colors.values())\n","  result_image = np.zeros((H, W, 3)).astype(np.uint)\n","  for h in range(H):\n","    for w in range(W):\n","      result_image[h,w,:] = label_values[label_map[h,w]]\n","  return result_image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DpG8L0zHqJNv"},"outputs":[],"source":["def get_pixel_accuracy_by_tensor(target_label, input_label):\n","  if target_label.shape != input_label.shape:\n","    print(\"Input Shape Error!\")\n","    return\n","  H, W = target_label.shape\n","  t_i = H * W\n","  correct_num = torch.count_nonzero(target_label == input_label)\n","  return correct_num / t_i"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bURG_pw1jSa-"},"outputs":[],"source":["from numpy.lib.arraysetops import union1d\n","def get_iou_by_tensor(target_label, input_label):\n","  if target_label.shape != input_label.shape:\n","    print(\"Input Shape Error!\")\n","    return\n","  class_list= torch.unique(target_label)\n","  class_num = len(class_list)\n","  H, W = target_label.shape\n","  class_iou = 0\n","  for i in class_list:\n","    target_i = target_label == i\n","    label_i = input_label == i\n","    num_target_i = torch.count_nonzero(target_i)\n","    num_label_i = torch.count_nonzero(label_i)\n","    intersection = torch.count_nonzero((target_i == True) & (label_i == True))\n","    union = num_target_i +  num_label_i - intersection\n","    if union != 0:\n","      class_iou += intersection / union\n","  result = class_iou / class_num\n","  return result"]},{"cell_type":"markdown","source":["# Get Result"],"metadata":{"id":"RCd0XLW-q_6k"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":93035,"status":"ok","timestamp":1654421403370,"user":{"displayName":"전준형","userId":"14189242397168360494"},"user_tz":-540},"id":"28NBcKpYlo1z","outputId":"a4e4cd02-2a84-4731-fa52-c652af377cae"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1098/1098 [01:34<00:00, 11.66it/s]\n"]}],"source":["from tqdm import tqdm\n","tqdm_var = tqdm(val_loader)\n","acc_pix2pix_list = []\n","iou_pix2pix_list = []\n","acc_cyclegan_list = []\n","iou_cyclegan_list = []\n","acc_semi_cyclegan_list = []\n","iou_semi_cyclegan_list = []\n","with torch.no_grad():\n","  for inputA, inputB in tqdm_var:\n","    inputA = inputA.to(device)\n","    inputB = inputB.to(device)\n","\n","    pix2pix_fake_B = pix2pix_netG(inputA)\n","    cyclegan_fake_B = default_netG_A2B(inputA)\n","    semi_cyclegan_fake_B = semi_netG_A2B(inputA)\n","\n","    input_label_map = make_label_map_by_torch(batch_tensor_to_image_tensor(inputB))\n","    pix2pix_label_map = make_label_map_by_torch(batch_tensor_to_image_tensor(pix2pix_fake_B))\n","    cyclegan_label_map = make_label_map_by_torch(batch_tensor_to_image_tensor(cyclegan_fake_B))\n","    semi_cyclegan_label_map = make_label_map_by_torch(batch_tensor_to_image_tensor(semi_cyclegan_fake_B))\n","  \n","    acc_pix2pix = get_pixel_accuracy_by_tensor(input_label_map, pix2pix_label_map)\n","    iou_pix2pix = get_iou_by_tensor(input_label_map, pix2pix_label_map)\n","    acc_cyclegan = get_pixel_accuracy_by_tensor(input_label_map, cyclegan_label_map)\n","    iou_cyclegan = get_iou_by_tensor(input_label_map, cyclegan_label_map)\n","    acc_semi_cyclegan = get_pixel_accuracy_by_tensor(input_label_map, semi_cyclegan_label_map)\n","    iou_semi_cyclegan = get_iou_by_tensor(input_label_map, semi_cyclegan_label_map)\n","    \n","    acc_pix2pix_list.append(acc_pix2pix)\n","    iou_pix2pix_list.append(iou_pix2pix)\n","    acc_cyclegan_list.append(acc_cyclegan)\n","    iou_cyclegan_list.append(iou_cyclegan)\n","    acc_semi_cyclegan_list.append(acc_semi_cyclegan)\n","    iou_semi_cyclegan_list.append(iou_semi_cyclegan)"]},{"cell_type":"markdown","source":["# Pixel Accuracy"],"metadata":{"id":"Z9bNRSlHrLDq"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":471,"status":"ok","timestamp":1654421403828,"user":{"displayName":"전준형","userId":"14189242397168360494"},"user_tz":-540},"id":"JPa81dKjrbBE","outputId":"4f8ae895-3ded-4607-b7c9-92ebaf1eb075"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.6243, device='cuda:0'),\n"," tensor(0.5818, device='cuda:0'),\n"," tensor(0.6657, device='cuda:0'))"]},"metadata":{},"execution_count":39}],"source":["pix2pix_pixel_acc = sum(acc_pix2pix_list) / len(acc_pix2pix_list) \n","cyclegan_pixel_acc = sum(acc_cyclegan_list) / len(acc_cyclegan_list) \n","semi_cyclegan_pixel_acc = sum(acc_semi_cyclegan_list) / len(acc_semi_cyclegan_list)\n","pix2pix_pixel_acc, cyclegan_pixel_acc, semi_cyclegan_pixel_acc"]},{"cell_type":"markdown","source":["# Mean IoU"],"metadata":{"id":"l2knKoxSrN3a"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1654421403828,"user":{"displayName":"전준형","userId":"14189242397168360494"},"user_tz":-540},"id":"O2SrWmZhZbOm","outputId":"464f7e5b-6840-4280-c690-21ea0f68cfec"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.2430, device='cuda:0'),\n"," tensor(0.2344, device='cuda:0'),\n"," tensor(0.2963, device='cuda:0'))"]},"metadata":{},"execution_count":40}],"source":["pix2pix_iou = sum(iou_pix2pix_list) / len(iou_pix2pix_list) \n","cyclegan_iou = sum(iou_cyclegan_list) / len(iou_cyclegan_list) \n","semi_cyclegan_iou = sum(iou_semi_cyclegan_list) / len(iou_semi_cyclegan_list) \n","pix2pix_iou,cyclegan_iou ,semi_cyclegan_iou"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Check Result_Maps.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}